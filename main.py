import streamlit as st
import os
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader, TextLoader
from streaming import StreamHandler
import utils

# st.spinnerë¥¼ ë„£ì–´ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•œê²Œ ì•„ë‹ˆë¼, 
# ê·¸ëƒ¥ VS codeì—ì„œ ìµœì´ˆë¡œ ì‹¤í–‰ ë° ë””ë²„ê·¸ í–ˆì„ ë• ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ë‹¤ê°€, ì±—ë´‡ í™”ë©´ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ api í‚¤ ì…ë ¥í•œ ë’¤ ì§ˆë¬¸í•˜ë©´ Referenceê°€ ì¤‘ë³µë˜ëŠ”ê±¸ ë°œê²¬í•¨.
# ì•„ì˜ˆ VS codeë¡œ ëŒì•„ì™€ì„œ ctrl + cë¡œ streamlit run ì¢…ë£Œí•˜ê³  ë‹¤ì‹œ ì‹¤í–‰ ë° ë””ë²„ê¹…í•˜ë©´ Reference ì •ìƒì‘ë™. í•œë²ˆ í•´ë´ì£¼ì„¸ìš”.

st.title("ë‹¹ë‡¨ í™˜ìë“¤ì„ ìœ„í•œ ì±—ë´‡ ğŸ’Š")
# openai key input gui. ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ë©ˆì¶¤ ìˆìœ¼ë©´ ê³„ì† ì§„í–‰
model_name = utils.configure_openai()


# qa_chain ìµœì´ˆë¡œ í•œë²ˆ ì •ì˜í•˜ê³  session_stateì— ì €ì¥í•´ë‘ .  os.environ['OPENAI_API_KEY'] ì—†ëŠ” ìƒíƒœë¡œ Chroma ê°ì²´ ìƒì„±í•˜ë©´ ì—ëŸ¬ë‚¨
if "qa_chain" not in st.session_state:
    with st.spinner('ë‹µë³€ì— í•„ìš”í•œ ë¬¸ì„œë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'):
    # ê° í™•ì¥ì ë³„ë¡œ ë¬¸ì„œ ë¡œë” ì •ì˜
        documents = []

        loaders = {
            'pdf': {'loader':PyMuPDFLoader, 'kwargs': {}},
            'txt': {'loader':TextLoader, 'kwargs': {'autodetect_encoding': True}}
        }
        for file_type, value in loaders.items():
            loader = value['loader']
            loader_kwargs = value['kwargs']

            loader = DirectoryLoader(path=f"data/{file_type}", glob=f"**/*.{file_type}",loader_cls=loader, loader_kwargs=loader_kwargs)
            documents.extend(loader.load())

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ê¸° ì •ì˜
        embedding = OpenAIEmbeddings()

        vectordb = Chroma.from_documents(
            documents=documents,
            embedding=embedding)

        retriever = vectordb.as_retriever()

        llm = ChatOpenAI(model_name=model_name, temperature=0, streaming=True)

        st.session_state["qa_chain"] = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True
        )


#chat gui
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë‹¹ë‡¨ë³‘ì— ê´€í•œ ì§ˆë¬¸ì„ ì£¼ì„¸ìš”!"}]

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])


user_query = st.chat_input(placeholder="ë‹¹ë‡¨ ê´€ë ¨ ì§ˆë¬¸í•˜ì„¸ìš”!")

if user_query:
    with st.chat_message("user"):
        st.session_state.messages.append({"role": "user", "content": user_query})
        st.write(user_query)

    with st.chat_message("assistant"):
        st_cb = StreamHandler(st.empty())
        result = st.session_state["qa_chain"].invoke(
            {"query":user_query},
            {"callbacks": [st_cb]}
        )
        response = result["result"]
        st.session_state.messages.append({"role": "assistant", "content": response})

        # to show references
        for idx, doc in enumerate(result['source_documents'],1):
            filename = os.path.basename(doc.metadata['source'])
            _, ext = os.path.splitext(filename)
        
            if ext == '.txt':
                ref_title = f":blue[Reference {idx}: *{filename}*]"
            elif ext == '.pdf':
                page_num = doc.metadata['page']
                ref_title = f":blue[Reference {idx}: *{filename} - page.{page_num}*]"

            with st.popover(ref_title):
                st.caption(doc.page_content)